{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this notebook I'm showing how these tables can be created from the base tables \n",
    "#through reading and extracting the data for each part and writing it back as a finished table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data_frame(sql:str, conn):\n",
    "    df = pd.read_sql_query(sql, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract connection parameters and established connection for reading\n",
    "db_config = {\n",
    "    'user': 'avnadmin',\n",
    "    'password': 'AVNS_4T0M1r4SdTxtoZAMUPL',\n",
    "    'host': 'mysql-c314d3b-reveliolab-assignment1.e.aivencloud.com',\n",
    "    'port': 24878,\n",
    "    'database':'INGESTION',\n",
    "    'ssl_disabled': False  # Enforces SSL connection\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Establish a connection\n",
    "    conn_read = mysql.connector.connect(**db_config)\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#established connection for writing \n",
    "db_url = 'mysql+pymysql://avnadmin:AVNS_4T0M1r4SdTxtoZAMUPL@mysql-c314d3b-reveliolab-assignment1.e.aivencloud.com:24878/INGESTION'\n",
    "engine = create_engine(\n",
    "    db_url,\n",
    "    connect_args={\"ssl\": {\"ssl-ca\": \"../ca.crt\"}} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select * from position_history where ENDDATE is NULL;\n",
    "\"\"\"\n",
    "df = export_data_frame(sql, conn_read)\n",
    "df_current = df[df['ENDDATE'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259629"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_current.to_sql('position_current', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\" \n",
    "SELECT \n",
    "    p.SCRAPE_TS as SCRAPE_TS,\n",
    "    p.USER_ID as USER_ID,\n",
    "    p.URI as URI,\n",
    "    p.POSITION_ID as POSITION_ID,\n",
    "    p.COMPANY_RAW as COMPANY_RAW,\n",
    "    p.COMPANYURI as COMPANYURI,\n",
    "    p.TITLE_RAW as TITLE_RAW,\n",
    "    p.LOCATION_RAW as LOCATION_RAW,\n",
    "    p.DESCRIPTION as DESCRIPTION,\n",
    "    p.STARTDATE as STARTDATE,\n",
    "    p.ENDDATE as ENDDATE,\n",
    "    p.SEQUENCENO as SEQUENCENO,\n",
    "    p.ORDER_IN_PROFILE as ORDER_IN_PROFILE,\n",
    "    -- Adding fields from location_mapper_v3\n",
    "    lm.CITY as CITY,\n",
    "    lm.STATE as STATE,\n",
    "    lm.STATE_ABBR as STATE_ABBR,\n",
    "    lm.COUNTRY as COUNTRY,\n",
    "    lm.METRO_AREA as METRO_AREA,\n",
    "    lm.REGION_NAME as REGION_NAME,\n",
    "    -- Adding RCID from company2rcid\n",
    "    c.RCID as RCID\n",
    "FROM position_current p\n",
    "LEFT JOIN location_mapper_v3 lm ON p.LOCATION_RAW = lm.LOCATION\n",
    "LEFT JOIN company2rcid c ON p.COMPANY_RAW = c.COMPANY;\n",
    "\"\"\"\n",
    "df = export_data_frame(sql, conn_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352311"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('individual_position', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/1nrqfd6x68gbp20pbwfzktv80000gn/T/ipykernel_23436/2898789021.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn)\n"
     ]
    }
   ],
   "source": [
    "#PART C\n",
    "\n",
    "sql = \"\"\" \n",
    "SELECT * FROM individual_position;\n",
    "\"\"\"\n",
    "df = export_data_frame(sql, conn_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by USER_ID and STARTDATE\n",
    "\n",
    "df = df.sort_values(by=['USER_ID', 'STARTDATE', 'ORDER_IN_PROFILE'])\n",
    "df = df.drop_duplicates(subset=['USER_ID', 'POSITION_ID', 'STARTDATE'])\n",
    "\n",
    "\n",
    "# Create the transition dataset by shifting rows within each USER_ID\n",
    "df[\"prev_POSITION_ID\"] = df.groupby(\"USER_ID\")[\"POSITION_ID\"].shift(1)\n",
    "df[\"prev_COMPANY_RAW\"] = df.groupby(\"USER_ID\")[\"COMPANY_RAW\"].shift(1)\n",
    "df[\"prev_COMPANYURI\"] = df.groupby(\"USER_ID\")[\"COMPANYURI\"].shift(1)\n",
    "df[\"prev_TITLE_RAW\"] = df.groupby(\"USER_ID\")[\"TITLE_RAW\"].shift(1)\n",
    "df[\"prev_LOCATION_RAW\"] = df.groupby(\"USER_ID\")[\"LOCATION_RAW\"].shift(1)\n",
    "df[\"prev_DESCRIPTION\"] = df.groupby(\"USER_ID\")[\"DESCRIPTION\"].shift(1)\n",
    "df[\"prev_STARTDATE\"] = df.groupby(\"USER_ID\")[\"STARTDATE\"].shift(1)\n",
    "df[\"prev_ENDDATE\"] = df.groupby(\"USER_ID\")[\"ENDDATE\"].shift(1)\n",
    "df[\"prev_SEQUENCENO\"] = df.groupby(\"USER_ID\")[\"SEQUENCENO\"].shift(1)\n",
    "df[\"prev_ORDER_IN_PROFILE\"] = df.groupby(\"USER_ID\")[\"ORDER_IN_PROFILE\"].shift(1)\n",
    "df[\"prev_CITY\"] = df.groupby(\"USER_ID\")[\"CITY\"].shift(1)\n",
    "df[\"prev_STATE\"] = df.groupby(\"USER_ID\")[\"STATE\"].shift(1)\n",
    "df[\"prev_STATE_ABBR\"] = df.groupby(\"USER_ID\")[\"STATE_ABBR\"].shift(1)\n",
    "df[\"prev_COUNTRY\"] = df.groupby(\"USER_ID\")[\"COUNTRY\"].shift(1)\n",
    "df[\"prev_METRO_AREA\"] = df.groupby(\"USER_ID\")[\"METRO_AREA\"].shift(1)\n",
    "df[\"prev_REGION_NAME\"] = df.groupby(\"USER_ID\")[\"REGION_NAME\"].shift(1)\n",
    "df[\"prev_RCID\"] = df.groupby(\"USER_ID\")[\"RCID\"].shift(1)\n",
    "\n",
    "# Remove rows where there's no previous position (i.e., first job)\n",
    "df_transitions = df.dropna(subset=[\"prev_POSITION_ID\"])\n",
    "\n",
    "# Rename current columns for clarity\n",
    "df_transitions = df_transitions.rename(columns={\n",
    "    \"POSITION_ID\": \"new_POSITION_ID\",\n",
    "    \"COMPANY_RAW\": \"new_COMPANY_RAW\",\n",
    "    \"COMPANYURI\": \"new_COMPANYURI\",\n",
    "    \"TITLE_RAW\": \"new_TITLE_RAW\",\n",
    "    \"LOCATION_RAW\": \"new_LOCATION_RAW\",\n",
    "    \"DESCRIPTION\": \"new_DESCRIPTION\",\n",
    "    \"STARTDATE\": \"new_STARTDATE\",\n",
    "    \"ENDDATE\": \"new_ENDDATE\",\n",
    "    \"SEQUENCENO\": \"new_SEQUENCENO\",\n",
    "    \"ORDER_IN_PROFILE\": \"new_ORDER_IN_PROFILE\",\n",
    "    \"CITY\": \"new_CITY\",\n",
    "    \"STATE\": \"new_STATE\",\n",
    "    \"STATE_ABBR\": \"new_STATE_ABBR\",\n",
    "    \"COUNTRY\": \"new_COUNTRY\",\n",
    "    \"METRO_AREA\": \"new_METRO_AREA\",\n",
    "    \"REGION_NAME\": \"new_REGION_NAME\",\n",
    "    \"RCID\": \"new_RCID\",\n",
    "})\n",
    "\n",
    "df_transitions = df_transitions[df_transitions['prev_POSITION_ID'] != df_transitions['new_POSITION_ID']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25307"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transitions.to_sql('transition_unique_base', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
